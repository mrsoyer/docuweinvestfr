# ğŸ”„ Flux de DonnÃ©es Back Office

## ğŸ¯ Vue d'ensemble

Le systÃ¨me de synchronisation des donnÃ©es Back Office de Weinvest repose sur 3 workflows n8n interconnectÃ©s qui assurent la synchronisation bidirectionnelle entre l'API Netty et la base de donnÃ©es Supabase. Ce systÃ¨me maintient une copie locale des donnÃ©es Netty pour les dashboards et analyses.

### ğŸ—ï¸ Architecture

```
Workflow 1 (Orchestrateur)
    â†“
Workflow 2 (ContrÃ´leur de pagination)
    â†“
Workflow 3 (Synchronisation des donnÃ©es)
```

### ğŸ“Š SchÃ©ma dÃ©taillÃ© du systÃ¨me

```mermaid
graph TB
    subgraph "Workflow 1 - Orchestrateur"
        A[Schedule Trigger<br/>10 min] --> B[Get Netty Tables<br/>SELECT netty-*]
        B --> C[Loop Over Tables<br/>splitInBatches]
        C --> D[HTTP Request<br/>webhook/backback]
    end
    
    subgraph "Workflow 2 - ContrÃ´leur"
        D --> E[Webhook backback]
        E --> F[Get Table Schema]
        F --> G[Get Last Modified Date]
        G --> H[Calculate Pagination<br/>page + time]
        H --> I[Call sync_back]
        I --> J{More data?}
        J -->|Yes| K[Loop back]
        K --> D
        J -->|No| L[End]
    end
    
    subgraph "Workflow 3 - Synchronisation"
        I --> M[Webhook sync_back]
        M --> N[Get Netty Data<br/>API Call]
        N --> O{Data found?}
        O -->|Yes| P[Prepare UPSERT SQL]
        P --> Q[Execute in Supabase]
        Q --> R[Return continue:1]
        O -->|No| S[Return continue:0]
    end
    
    subgraph "External Systems"
        T[Netty API] -.->|Data| N
        Q -.->|Store| U[Supabase DB]
    end
    
    style A fill:#e1f5fe
    style T fill:#fff3e0
    style U fill:#fff3e0
```

## ğŸ“Š Workflow 1 : Orchestrateur Principal

### ğŸ“Š Description
- **URL** : https://primary-production-b292d.up.railway.app/workflow/0rIHNzcwRFalRjXH
- **DÃ©clencheur** : Schedule Trigger toutes les 10 minutes
- **Objectif** : Identifier et lancer la synchronisation de toutes les tables Netty

### âš™ï¸ Ã‰tapes du processus

1. **Identification des tables Ã  synchroniser**
   ```sql
   SELECT table_name 
   FROM information_schema.tables 
   WHERE table_schema = 'public' 
   AND table_name LIKE 'netty-%'
   ```

2. **Boucle sur chaque table**
   - Utilisation du node `splitInBatches` pour traiter table par table
   - Appel sÃ©quentiel pour Ã©viter la surcharge

3. **DÃ©clenchement workflow 2**
   ```http
   GET https://primary-production-b292d.up.railway.app/webhook/backback
   ?table_name={table_name}
   ```

### ğŸ”„ Flux de donnÃ©es
- **Input** : Aucun (dÃ©clenchÃ© par schedule)
- **Output** : Liste des tables Ã  synchroniser
- **Volume** : ~10-20 tables selon configuration

## ğŸ“Š Workflow 2 : ContrÃ´leur de Pagination

### ğŸ“Š Description
- **URL** : https://primary-production-b292d.up.railway.app/workflow/DW4E8e480mUDm6ZU
- **Endpoint** : `/backback`
- **Objectif** : GÃ©rer la pagination et l'Ã©tat de synchronisation pour chaque table

### âš™ï¸ Ã‰tapes du processus

1. **RÃ©cupÃ©ration du schÃ©ma de table**
   ```sql
   SELECT 
       c.column_name,
       c.data_type,
       c.character_maximum_length,
       c.column_default,
       c.is_nullable,
       CASE 
           WHEN tc.constraint_type = 'PRIMARY KEY' THEN true 
           ELSE false 
       END as is_primary_key
   FROM information_schema.columns c
   LEFT JOIN information_schema.key_column_usage kcu 
       ON c.table_schema = kcu.table_schema 
       AND c.table_name = kcu.table_name 
       AND c.column_name = kcu.column_name
   LEFT JOIN information_schema.table_constraints tc 
       ON kcu.constraint_schema = tc.constraint_schema 
       AND kcu.constraint_name = tc.constraint_name
   WHERE 
       c.table_schema = 'public'
       AND c.table_name = '{table_name}'
   ORDER BY c.ordinal_position
   ```

2. **DÃ©termination de la date de derniÃ¨re modification**
   ```sql
   SELECT MAX(time_modified) as date_modification 
   FROM "{table_name}"
   ```

3. **Calcul de la pagination**
   ```javascript
   // Gestion de la page courante
   let currentNumber = 0;
   if ($("Code3")) {
     currentNumber = Number($("Code3").last().json.numlber);
   }
   
   // Ajustement du timestamp (UTC-2h)
   return { 
     page: currentNumber,
     time: new Date(new Date(lastModified).getTime() - 2 * 60 * 60 * 1000).toISOString()
   }
   ```

4. **Appel workflow 3 pour synchronisation**
   ```http
   POST https://primary-production-b292d.up.railway.app/webhook/sync_back
   ?table_name={table_name_sans_prefix}
   ?page={page}
   ?time={time}
   
   Body: {
     "shema": [schema_info]
   }
   ```

5. **Gestion de la continuation**
   - **If1** : VÃ©rifie si la date max locale est dÃ©passÃ©e
   - **If** : VÃ©rifie le flag `continue` (1 = plus de donnÃ©es)
   - Si oui â†’ rappel rÃ©cursif du workflow

### ğŸ”„ Ã‰tats de synchronisation
- **Continue = 1** : Il reste des pages Ã  synchroniser
- **Continue = 0** : Synchronisation terminÃ©e pour cette table
- **Timeout safety** : Ajout de 1h au timestamp pour Ã©viter les donnÃ©es manquÃ©es

## ğŸ“Š Workflow 3 : Synchronisation des DonnÃ©es

### ğŸ“Š Description
- **URL** : https://primary-production-b292d.up.railway.app/workflow/lbzJ5ONapGnSwt4A
- **Endpoint** : POST `/sync_back`
- **Objectif** : RÃ©cupÃ©rer et synchroniser les donnÃ©es page par page

### âš™ï¸ Ã‰tapes du processus

1. **RÃ©cupÃ©ration des donnÃ©es Netty**
   ```http
   GET https://webapi.netty.fr/apiv1/{table_name}
   Headers:
     x-netty-api-key: 41021a5a-a244-452b-af21-02d1d1672788
     accept: application/json
   Query:
     sort: time_modified:asc
     limit: 100
     offset: {page * 100}
     filters: time_modified:greater:{time - 2h}
   ```

2. **Traitement des donnÃ©es** (Node Prepare Data1)
   ```javascript
   // Structure de l'upsert
   const baseFields = {
     [primaryKey]: item[primaryKey],     // ClÃ© primaire
     data: dataObject,                   // JSON nettoyÃ©
     time_modified: item.time_modified,  // Timestamp
     time_created: item.time_created     // Timestamp
   };
   
   // Suppression des champs systÃ¨me du JSON data
   delete dataObject[primaryKey];
   delete dataObject.time_modified;
   delete dataObject.time_created;
   dataObject.deleted = item.deleted || false;
   ```

3. **GÃ©nÃ©ration SQL UPSERT**
   ```sql
   INSERT INTO "netty-{table_name}" (columns)
   VALUES (values)
   ON CONFLICT ("{primary_key}") DO UPDATE SET
     "data" = "netty-{table_name}"."data" || EXCLUDED."data",  -- Fusion JSONB
     "time_modified" = EXCLUDED."time_modified"
   ```

4. **Gestion de la rÃ©ponse**
   - Si donnÃ©es trouvÃ©es â†’ retour `continue: 1` avec derniÃ¨re `time_modified`
   - Si aucune donnÃ©e â†’ retour `continue: 0` avec time + 5h

### ğŸ“¦ Structure des tables Supabase

Toutes les tables `netty-*` suivent cette structure :
```sql
CREATE TABLE "netty-{nom}" (
  {primary_key} INTEGER PRIMARY KEY,
  data JSONB NOT NULL,
  time_created TIMESTAMP WITH TIME ZONE,
  time_modified TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT timezone('utc', now())
);
```

## ğŸ” SÃ©curitÃ© et Configuration

### ğŸ”‘ Credentials
- **Supabase PostgreSQL** : ID `88poxiTdcD5sbRv6`
- **Netty API Key** : `41021a5a-a244-452b-af21-02d1d1672788`

### â° ParamÃ¨tres temporels
- **Schedule** : Toutes les 10 minutes
- **Timeout HTTP** : 20 secondes
- **Retry** : ActivÃ© avec 5 secondes entre tentatives
- **DÃ©calage UTC** : -2h pour synchronisation avec Netty

### ğŸ›¡ï¸ Protection des donnÃ©es
- Utilisation de requÃªtes prÃ©parÃ©es (Ã©chappement SQL)
- Validation des schÃ©mas avant insertion
- Gestion des erreurs avec fallback NULL

## ğŸš¨ Points d'attention

### 1. **Gestion de la pagination**
- Limite de 100 items par page (API Netty)
- Pagination sÃ©quentielle pour Ã©viter les donnÃ©es manquÃ©es
- Reset automatique si dÃ©passement de date

### 2. **Fusion JSONB**
- La colonne `data` utilise l'opÃ©rateur `||` pour fusion
- PrÃ©serve les donnÃ©es existantes lors des updates
- Attention aux conflits de clÃ©s dans le JSON

### 3. **Performances**
- Traitement item par item (`runOnceForEachItem`)
- Pas de traitement parallÃ¨le pour Ã©viter les conflits
- Index recommandÃ©s sur `time_modified` et clÃ©s primaires

### 4. **DÃ©calage temporel**
- -2h systÃ©matique sur les requÃªtes Netty
- +1h de sÃ©curitÃ© sur la vÃ©rification locale
- +5h si aucune donnÃ©e (Ã©vite les boucles)

### 5. **Tables supportÃ©es**
Pattern de nommage : `netty-{nom_table}`
Tables courantes :
- `netty-users`
- `netty-agencies`
- `netty-properties`
- `netty-contacts`
- `netty-tasks`

## ğŸ“ˆ Monitoring et Maintenance

### ğŸ“Š MÃ©triques Ã  suivre
1. **DurÃ©e de synchronisation** par table
2. **Volume de donnÃ©es** synchronisÃ©es
3. **Erreurs de timeout** ou API
4. **DÃ©calage temporel** entre Netty et local

### ğŸ”§ Maintenance
- VÃ©rifier rÃ©guliÃ¨rement les logs n8n
- Monitorer l'espace disque Supabase
- Valider l'intÃ©gritÃ© des donnÃ©es JSONB
- Nettoyer les donnÃ©es obsolÃ¨tes (deleted = true)

### ğŸš€ Optimisations possibles
1. ParallÃ©lisation des tables indÃ©pendantes
2. Compression des donnÃ©es JSONB anciennes
3. Archivage des donnÃ©es > 1 an
4. Index sur les champs JSON frÃ©quemment requÃªtÃ©s

## ğŸ”„ Flux de synchronisation complet

```
Schedule (10 min)
    â†“
[Workflow 1] Liste tables netty-*
    â†“
Pour chaque table:
    â†“
[Workflow 2] Get schema + last modified
    â†“
[Workflow 3] Page 0 â†’ Get 100 items â†’ Upsert
    â†“
Continue? â†’ [Workflow 3] Page 1 â†’ Get 100 items â†’ Upsert
    â†“
... jusqu'Ã  continue = 0
    â†“
Table suivante
```

### ğŸ“Š SchÃ©ma de flux de donnÃ©es

```mermaid
graph LR
    subgraph "Source Netty"
        A1[users API]
        A2[agencies API]
        A3[properties API]
        A4[contacts API]
        A5[tasks API]
    end
    
    subgraph "Synchronisation n8n"
        B[Workflow 1<br/>Orchestrateur]
        B --> C[Workflow 2<br/>Pagination]
        C --> D[Workflow 3<br/>Sync Data]
        D --> E{Continue?}
        E -->|Yes| C
        E -->|No| F[Next Table]
        F --> B
    end
    
    subgraph "Destination Supabase"
        G1[netty-users]
        G2[netty-agencies]
        G3[netty-properties]
        G4[netty-contacts]
        G5[netty-tasks]
    end
    
    A1 -.->|100/page| D
    A2 -.->|100/page| D
    A3 -.->|100/page| D
    A4 -.->|100/page| D
    A5 -.->|100/page| D
    
    D -->|UPSERT| G1
    D -->|UPSERT| G2
    D -->|UPSERT| G3
    D -->|UPSERT| G4
    D -->|UPSERT| G5
    
    style B fill:#e1f5fe
    style C fill:#e1f5fe
    style D fill:#e1f5fe
```

### ğŸ“Š Structure des donnÃ©es synchronisÃ©es

```mermaid
erDiagram
    NETTY_TABLE {
        integer primary_key PK
        jsonb data
        timestamp time_created
        timestamp time_modified
        timestamp created_at
    }
    
    DATA_JSONB {
        string field1
        string field2
        boolean deleted
        json nested_data
        array relationships
    }
    
    NETTY_TABLE ||--|| DATA_JSONB : contains
    
    EXAMPLE_USERS {
        integer user_id PK
        jsonb data
        timestamp time_created
        timestamp time_modified
    }
    
    USER_DATA {
        string first_name
        string last_name
        string email
        string phone
        integer linked_company_id
        boolean activated
        boolean deleted
    }
    
    EXAMPLE_USERS ||--|| USER_DATA : stores
```

## ğŸ› ï¸ DÃ©pannage

### ProblÃ¨mes courants

1. **Timeout sur grandes tables**
   - Augmenter timeout dans HTTP Request
   - RÃ©duire la limite Ã  50 items

2. **DonnÃ©es manquantes**
   - VÃ©rifier le dÃ©calage temporel
   - Forcer resync avec time = NULL

3. **Erreurs JSONB**
   - Valider le JSON avant insertion
   - Ã‰chapper correctement les apostrophes

4. **Boucle infinie**
   - VÃ©rifier la logique continue
   - Limiter le nombre de pages max 